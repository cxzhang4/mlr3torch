% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/PipeOpTaskPreprocTorch.R
\name{mlr_pipeops_preproc_torch}
\alias{mlr_pipeops_preproc_torch}
\alias{PipeOpTaskPreprocTorch}
\title{Base Class for Torch Preprocessing}
\description{
This \code{PipeOp} can be used to preprocess (one or more) \code{\link{lazy_tensor}} columns contained in an \code{\link[mlr3:Task]{mlr3::Task}}.
The function that is applied is specified as construction argument \code{fn} and additional arguments to this
function can be defined through the \code{PipeOp}'s parameter set.
The preprocessing is either done per-column in which case the number lazy tensor output columns is equivalent
to the number of lazy tensor input columns.
It is also possible to implement preprocessing that is applied to all lazy tensor columns at once and returns
one or more (not necessarily the same number) of lazy tensor columns.
}
\section{Inheriting}{

In addition to specifying the parameters \code{fn}, \code{packages} and \code{param_set} during construction you can also overwrite
the private \code{.shapes_out()} or \code{.tranform()} methods:
\itemize{
\item \code{.shapes_out(shapes_in, param_vals, task)}\cr
(\code{list()}, \verb{list(), }Task\code{or}NULL\verb{) -> }list()`\cr
This private method calculates the output shapes of the lazy tensor columns that are created from applying
the preprocessing.

Also see the documentation of \code{\link{PipeOpTorch}} how to implement this method.

In case the construction argument \code{per_column} is \code{TRUE}, this private method only has the responsibility
to caclculate the output shapes for one input column, i.e. the input \code{shapes_in} can be assumed to have
exactly one shape vector for which it must calculate the output shapes.
\item \code{.transform(dt, task, param_vals, stage)}\cr
(\code{data.table()}, \code{Task}, \code{list()}, \code{character(1)}) -> \code{data.table()}\cr
This method must only be overwritten when the the \code{per_column} construction argument is \code{FALSE}.
It receives as inputs all selected lazy tensor columns, the input \code{Task} (already cloned),
the paramer values, and whether the preprocessing is applied during training (stage is \code{"train"})
or prediction (stage is \code{"predict"}). It needs to return a \code{data.table} with lazy tensor columns.
Note that the lazy tensor inputs should not be modified in-place.
Note that overwriting this method (currently) requires a solid understanding of the \code{\link{lazy_tensor}} internals. This might be made easier in the future.
Note also that you need to pay attention to avoid name conflicts with existing columns in the task.
}
}

\section{Input and Output Channels}{

See \code{\link{PipeOpTaskPreproc}}.
}

\section{State}{

See \code{\link{PipeOpTaskPreproc}}.
}

\section{Parameters}{

In addition to the parameters inherited from \code{\link{PipeOpTaskPreproc}} as well as those specified during construction
as the argument \code{param_set} there are the following parameters:
\itemize{
\item \code{augment} :: \code{logical(1)}\cr
(This parameter only exists of the \code{PipeOp}) is applied per column.
Whether the to apply the preprocessing only during training (\code{TRUE}) or also during prediction (\code{FALSE}).
This parameter is initialized to \code{FALSE}.
}
}

\section{Internals}{

If \code{per_column} is \code{TRUE}:

A \code{\link{PipeOpModule}} with one input and one output channel is created.
The pipeop simply applies the function \code{fn} to the input tensor while additionally
passing the paramter values (minus \code{augment} and \code{affect_columns}) to \code{fn}.
Then \code{\link{transform_lazy_tensor}} is called with the created \code{\link{PipeOpModule}} and the shapes obtained from the
\verb{$shapes_out()} method of this \code{PipeOp}.

If \code{per_column} is \code{FALSE}:
It is the obligation of the user to overwrite the \code{.transform()} method appropriately.
Note that on
}

\examples{
# Creating a simple task
d = data.table(
  x1 = as_lazy_tensor(rnorm(10)),
  x2 = as_lazy_tensor(rnorm(10)),
  x3 = as_lazy_tensor(as.double(1:10)),
  y = rnorm(10)
)

taskin = as_task_regr(d, target = "y")

# Creating a simple preprocessing pipeop
po_simple = po("preproc_torch",
  # use mlr3misc::crate to get rid of unnecessary environment baggage
  fn = mlr3misc::crate(function(x, a) x + a),
  param_set = ps(a = p_int(tags = c("train", "predict", "required")))
)

po_simple$param_set$set_values(
  a = 100,
  affect_columns = selector_name(c("x1", "x2")),
  augment = FALSE
)

taskout_train = po_simple$train(list(taskin))[[1L]]
materialize(taskout_train$data(cols = c("x1", "x2")))

taskout_predict_noaug = po_simple$predict(list(taskin))[[1L]]
materialize(taskout_predict_noaug$data(cols = c("x1", "x2")))

po_simple$param_set$set_values(
  augment = TRUE
)

# transformation is not applied
taskout_predict_aug = po_simple$predict(list(taskin))[[1L]]
materialize(taskout_predict_aug$data(cols = c("x1", "x2")))

# Creating a more complex preprocessing PipeOp

PipeOpPreprocTorchPoly = R6::R6Class("PipeOpPreprocTorchPoly",
  inherit = PipeOpTaskPreprocTorch,
  public = list(
    initialize = function(id = "preproc_poly", param_vals = list()) {
      param_set = paradox::ps(
        n_degree = paradox::p_int(lower = 1L, tags = c("train", "predict", "required"))
      )
      param_set$set_values(
        n_degree = 1L
      )
      fn = mlr3misc::crate(function(x, n_degree) {
        torch::torch_cat(
          lapply(seq_len(n_degree), function(d) torch_pow(x, d)),
          dim = 2L
        )
      })

      super$initialize(
        fn = fn,
        id = id,
        packages = character(0),
        param_vals = param_vals,
        param_set = param_set
      )
    }
  ),
  private = list(
    .shapes_out = function(shapes_in, param_vals, task) {
      # shapes_in is a list of length 1 containing the shapes
      checkmate::assert_true(length(shapes_in[[1L]]) == 2L)
      if (shapes_in[[1L]][2L] != 1L) {
        stop("Input shape must be (NA, 1)")
      }
      list(c(NA, param_vals$n_degree))
    }
  )
)

po_poly = PipeOpPreprocTorchPoly$new(
  param_vals = list(n_degree = 3L, affect_columns = selector_name("x3"))
)

# Note that the 'augment' parameter is not present as the PipeOp
# modifies the input shape and must hence be applied during training **and** prediction
po_poly$param_set

po_poly$shapes_out(list(c(NA, 1L)))

taskout = po_poly$train(list(taskin))[[1L]]
materialize(taskout$data(cols = "x3"))
}
\section{Super classes}{
\code{\link[mlr3pipelines:PipeOp]{mlr3pipelines::PipeOp}} -> \code{\link[mlr3pipelines:PipeOpTaskPreproc]{mlr3pipelines::PipeOpTaskPreproc}} -> \code{PipeOpTaskPreprocTorch}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-PipeOpTaskPreprocTorch-new}{\code{PipeOpTaskPreprocTorch$new()}}
\item \href{#method-PipeOpTaskPreprocTorch-shapes_out}{\code{PipeOpTaskPreprocTorch$shapes_out()}}
\item \href{#method-PipeOpTaskPreprocTorch-clone}{\code{PipeOpTaskPreprocTorch$clone()}}
}
}
\if{html}{\out{
<details open><summary>Inherited methods</summary>
<ul>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="help"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-help'><code>mlr3pipelines::PipeOp$help()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="predict"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-predict'><code>mlr3pipelines::PipeOp$predict()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="print"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-print'><code>mlr3pipelines::PipeOp$print()</code></a></span></li>
<li><span class="pkg-link" data-pkg="mlr3pipelines" data-topic="PipeOp" data-id="train"><a href='../../mlr3pipelines/html/PipeOp.html#method-PipeOp-train'><code>mlr3pipelines::PipeOp$train()</code></a></span></li>
</ul>
</details>
}}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-PipeOpTaskPreprocTorch-new"></a>}}
\if{latex}{\out{\hypertarget{method-PipeOpTaskPreprocTorch-new}{}}}
\subsection{Method \code{new()}}{
Creates a new instance of this \code{\link[R6:R6Class]{R6}} class.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{PipeOpTaskPreprocTorch$new(
  fn,
  id = "preproc_torch",
  param_vals = list(),
  param_set = ps(),
  packages = character(0),
  per_column = TRUE,
  augment_init = FALSE
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{fn}}{(\code{function})\cr
The preprocessing function.}

\item{\code{id}}{(\code{character(1)})\cr
The id for of the new object.}

\item{\code{param_vals}}{(named \code{list()})\cr
Parameter values to be set after construction.}

\item{\code{param_set}}{(\code{\link{ParamSet}})\cr
In case the function \code{fn} takes additional parameter besides a \code{\link[=torch_tensor]{torch_tensor()}} they can be
specfied as parameters. Pay attention to set the correct \code{tags} for the parameters: if tag \code{"train"} is present,
the preprocessing is applied during training and if tag \code{"predict"} is present, the preprocessing is applied
during prediction (if \code{augment} is set to \code{FALSE}).}

\item{\code{packages}}{(\code{character()})\cr
The packages the preprocessing function depends on.}

\item{\code{per_column}}{(\code{logical(1)})\cr
Whether the transformation is applied per column.
If this is \code{FALSE}, is applied to all lazy tensor columns at once and might produce
one or more new lazy tensor columns.}

\item{\code{augment_init}}{(\code{logical(1)})\cr
Initial value for the \code{augment} parameter.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-PipeOpTaskPreprocTorch-shapes_out"></a>}}
\if{latex}{\out{\hypertarget{method-PipeOpTaskPreprocTorch-shapes_out}{}}}
\subsection{Method \code{shapes_out()}}{
Calculates the output shapes that would result in applying the preprocessing to one or more
lazy tensor columns with the provided shape.
Names are ignored and only order matters.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{PipeOpTaskPreprocTorch$shapes_out(shapes_in, stage = NULL, task = NULL)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{shapes_in}}{(\code{list()} of \code{integer()})\cr
The input input shapes of the lazy tensors.}

\item{\code{stage}}{(\code{character(1)})\cr
The stage: either \code{"train"} or \code{"predict"}.}

\item{\code{task}}{(\code{\link{Task}} or \code{NULL})\cr
The task, which is very rarely needed.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
\code{list()} of \code{integer()}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-PipeOpTaskPreprocTorch-clone"></a>}}
\if{latex}{\out{\hypertarget{method-PipeOpTaskPreprocTorch-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{PipeOpTaskPreprocTorch$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
